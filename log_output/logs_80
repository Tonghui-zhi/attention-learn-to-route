nohup: ignoring input
2024-07-23 13:07:02.748169: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-23 13:07:12.188269: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
{'baseline': 'rollout',
 'batch_size': 50,
 'bl_alpha': 0.05,
 'bl_warmup_epochs': 1,
 'checkpoint_encoder': False,
 'checkpoint_epochs': 1,
 'data_distribution': None,
 'embedding_dim': 128,
 'epoch_size': 1000,
 'epoch_start': 0,
 'eval_batch_size': 20,
 'eval_only': False,
 'exp_beta': 0.8,
 'graph_size': 80,
 'hidden_dim': 128,
 'load_path': None,
 'log_dir': 'logs',
 'log_step': 50,
 'lr_critic': 0.0001,
 'lr_decay': 1.0,
 'lr_model': 0.0001,
 'max_grad_norm': 1.0,
 'model': 'attention',
 'n_encode_layers': 3,
 'n_epochs': 100,
 'no_cuda': False,
 'no_progress_bar': False,
 'no_tensorboard': False,
 'normalization': 'batch',
 'output_dir': 'outputs',
 'problem': 'kf',
 'resume': None,
 'run_name': 'run_20240723T130820',
 'save_dir': 'outputs\\kf_80\\run_20240723T130820',
 'seed': 1234,
 'shrink_size': None,
 'tanh_clipping': 10.0,
 'use_cuda': False,
 'val_dataset': None,
 'val_size': 20}
Evaluating baseline model on evaluation dataset
  0%|          | 0/1 [00:00<?, ?it/s]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 1/1 [00:05<00:00,  5.21s/it]100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 1/1 [00:05<00:00,  5.21s/it]
Start train epoch 0, lr=0.0001 for run run_20240723T130820
  0%|          | 0/20 [00:00<?, ?it/s]2024-07-23 13:09:07.604530: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-23 13:09:24.802144: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
  0%|          | 0/20 [02:29<?, ?it/s]
Traceback (most recent call last):
  File "D:\zhitonghui1\project\PycharmProjects\kefu_assignment_algo\attention-learn-to-route\run.py", line 172, in <module>
    run(get_options())
  File "D:\zhitonghui1\project\PycharmProjects\kefu_assignment_algo\attention-learn-to-route\run.py", line 158, in run
    train_epoch(
  File "D:\zhitonghui1\project\PycharmProjects\kefu_assignment_algo\attention-learn-to-route\train.py", line 86, in train_epoch
    train_batch(
  File "D:\zhitonghui1\project\PycharmProjects\kefu_assignment_algo\attention-learn-to-route\train.py", line 154, in train_batch
    loss.backward()
  File "D:\zhitonghui1\project\PycharmProjects\attention-learn-to-route\env\lib\site-packages\torch\_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "D:\zhitonghui1\project\PycharmProjects\attention-learn-to-route\env\lib\site-packages\torch\autograd\__init__.py", line 267, in backward
    _engine_run_backward(
  File "D:\zhitonghui1\project\PycharmProjects\attention-learn-to-route\env\lib\site-packages\torch\autograd\graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2073600 bytes.
